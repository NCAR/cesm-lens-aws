{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This Jupyter Notebook demonstrates how one might use the NCAR Community Earth System Model (CESM)\n",
    "Large Ensemble (LENS) data hosted on AWS S3 ([doi:10.26024/wt24-5j82](https://doi.org/10.26024/wt24-5j82)). The notebook shows how to reproduce figures 2 and 4 from the Kay et al. (2015) paper describing the CESM LENS dataset ([doi:10.1175/BAMS-D-13-00255.1](https://doi.org/10.1175/BAMS-D-13-00255.1))\n",
    "\n",
    "This resource is intended to be helpful for people not familiar with elements of the [Pangeo](https://pangeo.io) framework including Jupyter Notebooks, [Xarray](http://xarray.pydata.org/), and [Zarr](https://zarr.readthedocs.io/) data format, or with the original paper, so it includes additional explanation.\n",
    "\n",
    "Notebook version 3.3 (2019 Dec 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display output of plots directly in Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Silence dask.distributed logs\n",
    "import logging\n",
    "logger = logging.getLogger(\"distributed.utils_perf\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "import dask.config\n",
    "dask.config.set({'distributed.logging.distributed': 'error'})\n",
    "\n",
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Connect to Dask Distributed Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client\n",
    "cluster = KubeCluster()\n",
    "cluster.adapt(minimum=2, maximum=100, wait_count=60)\n",
    "# Connect to cluster\n",
    "client = Client(cluster)\n",
    "# Display cluster dashboard URL\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "☝️ Link to scheduler dashboard will appear above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into xarray from a catalog using intake-esm\n",
    "\n",
    "- [Intake-esm Documentation](https://intake-esm.readthedocs.io/en/latest/notebooks/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open collection description file\n",
    "intakeEsmUrl = 'https://ncar-cesm-lens.s3-us-west-2.amazonaws.com/catalogs/aws-cesm1-le.json'\n",
    "col = intake.open_esm_datastore(intakeEsmUrl)\n",
    "print(col._col_data['description']) #Description of collection\n",
    "print(\"Catalog file:\", col._col_data['catalog_file'])\n",
    "print(col) #Summary of collection structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show expanded version of collection structure with details\n",
    "import pprint\n",
    "uniques = col.unique(columns=[\"component\", \"frequency\", \"experiment\", \"variable\"])\n",
    "pprint.pprint(uniques, compact=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few lines of the catalog\n",
    "col.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: inspect the collection object\n",
    "#import inspect\n",
    "#inspect.getmembers(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data needed to construct Figure 2 of Kay et al. paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the catalog to find the desired data, in this case the reference height temperature\n",
    "# of the atmosphere, at daily time resolution, for the Historical, 20th Century, and RCP8.5 (IPCC\n",
    "# Representative Concentration Pathway 8.5) experiments\n",
    "col_subset = col.search(frequency=[\"daily\", \"monthly\"], component=\"atm\", variable=\"TREFHT\", \n",
    "                        experiment=[\"20C\", \"RCP85\", \"HIST\"])\n",
    "print(\"Data subset:\")\n",
    "col_subset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalog entries for subset into a dictionary of xarray datasets\n",
    "dsets = col_subset.to_dataset_dict(zarr_kwargs={\"consolidated\": True}, storage_options={\"anon\": True})\n",
    "print(\"\\nDataset dictionary keys:\\n\", dsets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Xarray datasets corresponding to the three experiments\n",
    "ds_HIST = dsets['atm.HIST.monthly']\n",
    "ds_20C = dsets['atm.20C.daily']\n",
    "ds_RCP85 = dsets['atm.RCP85.daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Dask.Distributed utility function to display size of each dataset\n",
    "from distributed.utils import format_bytes\n",
    "print(\"\\n\",\n",
    "      \"Historical:\", format_bytes(ds_HIST.nbytes), \"\\n\",\n",
    "      \"20th Century:\", format_bytes(ds_20C.nbytes), \"\\n\",\n",
    "      \"RCP8.5:\", format_bytes(ds_RCP85.nbytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Reference Height Temperature data variable\n",
    "t_hist = ds_HIST[\"TREFHT\"]\n",
    "t_20c = ds_20C[\"TREFHT\"]\n",
    "t_rcp = ds_RCP85[\"TREFHT\"]\n",
    "print(\"Description of 20C data:\\n\", t_20c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The global surface temperature anomaly was computed relative to the 1961-90 base period\n",
    "# in the Kay et al. paper, so extract that time slice\n",
    "t_ref = t_20c.sel(time=slice(\"1961\", \"1990\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read grid cell areas\n",
    "Cell size varies with latitude, so this must be accounted for when computing the global mean.\n",
    "\n",
    "Note: Each Zarr store includes area values and other ancillary information in addition to the\n",
    "actual data. A possible optimization to reduce data size would be to extract the duplicated\n",
    "information into separate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_area = ds_20C.area\n",
    "total_area = cell_area.sum()\n",
    "cell_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Weighted Means\n",
    "Note: resample(time=\"AS\") does an Annual resampling based on Start of calendar year.\n",
    "See documentation for [Pandas resampling options](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ref_ts = (\n",
    "    (t_ref.resample(time=\"AS\").mean(\"time\") * cell_area).sum(dim=(\"lat\", \"lon\"))\n",
    "    / total_area\n",
    ").mean(dim=(\"time\", \"member_id\"))\n",
    "\n",
    "t_hist_ts = (\n",
    "    (t_hist.resample(time=\"AS\").mean(\"time\") * cell_area).sum(dim=(\"lat\", \"lon\"))\n",
    ") / total_area\n",
    "\n",
    "t_20c_ts = (\n",
    "    (t_20c.resample(time=\"AS\").mean(\"time\") * cell_area).sum(dim=(\"lat\", \"lon\"))\n",
    ") / total_area\n",
    "\n",
    "t_rcp_ts = (\n",
    "    (t_rcp.resample(time=\"AS\").mean(\"time\") * cell_area).sum(dim=(\"lat\", \"lon\"))\n",
    ") / total_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and compute means\n",
    "Note: Pangeo's \"lazy execution\" philosophy means that until this point we have not actually read the bulk of the data. These steps take a while to complete, so we include the Notebook \"cell magic\" directive %%time to display elapsed and CPU times after computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_ref_mean = t_ref_ts.load()\n",
    "t_ref_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_hist_ts_df = t_hist_ts.to_series().T\n",
    "t_hist_ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_20c_ts_df = t_20c_ts.to_series().unstack().T\n",
    "t_20c_ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_rcp_ts_df = t_rcp_ts.to_series().unstack().T\n",
    "t_rcp_ts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Observations for Figure 2 (HadCRUT4; Morice et al. 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observational time series data for comparison with ensemble average\n",
    "obsDataURL = \"https://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/cru/hadcrut4/air.mon.anom.median.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(obsDataURL).load()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Obs mean: weight by days in each month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_temporal_mean(ds):\n",
    "    time_bound_diff = ds.time_bnds.diff(dim=\"nbnds\")[:, 0]\n",
    "    wgts = time_bound_diff.groupby(\"time.year\") / time_bound_diff.groupby(\n",
    "        \"time.year\"\n",
    "    ).sum(xr.ALL_DIMS)\n",
    "    np.testing.assert_allclose(wgts.groupby(\"time.year\").sum(xr.ALL_DIMS), 1.0)\n",
    "    obs = ds[\"air\"]\n",
    "    cond = obs.isnull()\n",
    "    ones = xr.where(cond, 0.0, 1.0)\n",
    "    obs_sum = (obs * wgts).resample(time=\"AS\").sum(dim=\"time\")\n",
    "    ones_out = (ones * wgts).resample(time=\"AS\").sum(dim=\"time\")\n",
    "    obs_s = (obs_sum / ones_out).mean((\"lat\", \"lon\")).to_series()\n",
    "    return obs_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Limit Observations to 20th Century**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_s = weighted_temporal_mean(ds)\n",
    "obs_s = obs_s['1920':]\n",
    "obs_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ts_anom = pd.concat([t_20c_ts_df, t_rcp_ts_df]) - t_ref_mean.data\n",
    "years = [val.year for val in all_ts_anom.index]\n",
    "obs_years = [val.year for val in obs_s.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ensemble member 1 data from historical and 20th century experiments\n",
    "hist_anom = t_hist_ts_df - t_ref_mean.data\n",
    "member1 = pd.concat([hist_anom.iloc[:-2], all_ts_anom.iloc[:,0]], verify_integrity=True)\n",
    "member1_years = [val.year for val in member1.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Global surface temperature anomaly (1961-90 base period) for individual ensemble members, and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "\n",
    "ax.tick_params(right=True, top=True, direction=\"out\", length=6, width=2, grid_alpha=0.5)\n",
    "ax.plot(years, all_ts_anom.iloc[:,1:], color=\"grey\")\n",
    "ax.plot(obs_years, obs_s['1920':], color=\"red\")\n",
    "ax.plot(member1_years, member1, color=\"black\")\n",
    "\n",
    "\n",
    "ax.text(\n",
    "    0.35,\n",
    "    0.4,\n",
    "    \"observations\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    horizontalalignment=\"left\",\n",
    "    transform=ax.transAxes,\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    ")\n",
    "ax.text(\n",
    "    0.35,\n",
    "    0.33,\n",
    "    \"members 2-40\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    horizontalalignment=\"left\",\n",
    "    transform=ax.transAxes,\n",
    "    color=\"grey\",\n",
    "    fontsize=10,\n",
    ")\n",
    "ax.text(\n",
    "    0.05,\n",
    "    0.2,\n",
    "    \"member 1\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    horizontalalignment=\"left\",\n",
    "    transform=ax.transAxes,\n",
    "    color=\"black\",\n",
    "    fontsize=10,\n",
    ")\n",
    "\n",
    "ax.set_xticks([1850, 1920, 1950, 2000, 2050, 2100])\n",
    "plt.ylim(-1, 5)\n",
    "plt.xlim(1850, 2100)\n",
    "plt.ylabel(\"Global Surface\\nTemperature Anomaly (K)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure will appear above when ready. Compare with Fig.2 of Kay et al. 2015 ([doi:10.1175/BAMS-D-13-00255.1](https://doi.org/10.1175/BAMS-D-13-00255.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Linear Trend for Winter Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_trend(da, dim=\"time\"):\n",
    "    da_chunk = da.chunk({dim: -1})\n",
    "    trend = xr.apply_ufunc(\n",
    "        calc_slope,\n",
    "        da_chunk,\n",
    "        vectorize=True,\n",
    "        input_core_dims=[[dim]],\n",
    "        output_core_dims=[[]],\n",
    "        output_dtypes=[np.float],\n",
    "        dask=\"parallelized\",\n",
    "    )\n",
    "    return trend\n",
    "\n",
    "\n",
    "def calc_slope(y):\n",
    "    \"\"\"ufunc to be used by linear_trend\"\"\"\n",
    "    x = np.arange(len(y))\n",
    "\n",
    "    # drop missing values (NaNs) from x and y\n",
    "    finite_indexes = ~np.isnan(y)\n",
    "    slope = np.nan if (np.sum(finite_indexes) < 2) else np.polyfit(x[finite_indexes], y[finite_indexes], 1)[0]\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ensemble trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = xr.concat([t_20c, t_rcp], dim=\"time\")\n",
    "seasons = t.sel(time=slice(\"1979\", \"2012\")).resample(time=\"QS-DEC\").mean(\"time\")\n",
    "# Include only full seasons from 1979 and 2012\n",
    "seasons = seasons.sel(time=slice(\"1979\", \"2012\")).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_seasons = seasons.sel(\n",
    "    time=seasons.time.where(seasons.time.dt.month == 12, drop=True)\n",
    ")\n",
    "winter_trends = linear_trend(\n",
    "    winter_seasons.chunk({\"lat\": 20, \"lon\": 20, \"time\": -1})\n",
    ").load() * len(winter_seasons.time)\n",
    "\n",
    "# Compute ensemble mean from the first 30 members\n",
    "winter_trends_mean = winter_trends.isel(member_id=range(30)).mean(dim='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that we have 34 seasons\n",
    "assert len(winter_seasons.time) == 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Observations for Figure 4 (NASA GISS GisTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observational time series data for comparison with ensemble average\n",
    "# NASA GISS Surface Temperature Analysis, https://data.giss.nasa.gov/gistemp/\n",
    "obsDataURL = \"https://data.giss.nasa.gov/pub/gistemp/gistemp1200_GHCNv4_ERSSTv5.nc.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download, unzip, and load file\n",
    "import os\n",
    "os.system(\"wget \" + obsDataURL)\n",
    "\n",
    "obsDataFileName = obsDataURL.split('/')[-1]\n",
    "os.system(\"gunzip \" + obsDataFileName)\n",
    "\n",
    "obsDataFileName = obsDataFileName[:-3]\n",
    "ds = xr.open_dataset(obsDataFileName).load()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap longitude range from [-180, 180] to [0, 360] for plotting purposes\n",
    "ds = ds.assign_coords(lon=((ds.lon + 360) % 360)).sortby('lon')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute observed trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_seasons = ds.sel(time=slice(\"1979\", \"2012\")).resample(time=\"QS-DEC\").mean(\"time\")\n",
    "# Include only full seasons from 1979 through 2012\n",
    "obs_seasons = obs_seasons.sel(time=slice(\"1979\", \"2012\")).load()\n",
    "\n",
    "# Compute observed winter trends\n",
    "obs_winter_seasons = obs_seasons.sel(\n",
    "    time=obs_seasons.time.where(obs_seasons.time.dt.month == 12, drop=True)\n",
    ")\n",
    "obs_winter_seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_winter_trends = linear_trend(\n",
    "    obs_winter_seasons.chunk({\"lat\": 20, \"lon\": 20, \"time\": -1})\n",
    ").load() * len(obs_winter_seasons.time)\n",
    "obs_winter_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: Global maps of historical (1979 - 2012) boreal winter (DJF) surface air trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmaps  # for NCL colormaps\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "contour_levels = [-6, -5, -4, -3, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 3, 4, 5, 6]\n",
    "\n",
    "color_map = cmaps.ncl_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_map_plot(nplot_rows, nplot_cols, plot_index, data, plot_label):\n",
    "    \"\"\" Create a single map subplot. \"\"\"\n",
    "    ax = plt.subplot(nplot_rows, nplot_cols, plot_index, projection = ccrs.Robinson(central_longitude = 180))\n",
    "    cplot = plt.contourf(lons, lats, data, \n",
    "                         levels = contour_levels, \n",
    "                         cmap = color_map, \n",
    "                         extend = 'both', \n",
    "                         transform = ccrs.PlateCarree())\n",
    "    ax.coastlines(color = 'grey')\n",
    "    ax.text(0.01, 0.01, plot_label, fontSize = 14, transform = ax.transAxes)\n",
    "    return cplot, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plot (may take a while as many individual maps are generated)\n",
    "numPlotRows = 8\n",
    "numPlotCols = 4\n",
    "figWidth = 20 \n",
    "figHeight = 30 \n",
    " \n",
    "fig, axs = plt.subplots(numPlotRows, numPlotCols, figsize=(figWidth,figHeight))\n",
    "\n",
    "lats = winter_trends.lat\n",
    "lons = winter_trends.lon\n",
    "\n",
    "# Create ensemble member plots\n",
    "for ensemble_index in range(30):\n",
    "    plot_data = winter_trends.isel(member_id = ensemble_index)\n",
    "    plot_index = ensemble_index + 1\n",
    "    plot_label = str(plot_index)\n",
    "    plotRow = ensemble_index // numPlotCols\n",
    "    plotCol = ensemble_index % numPlotCols\n",
    "    # Retain axes objects for figure colorbar\n",
    "    cplot, axs[plotRow, plotCol] = make_map_plot(numPlotRows, numPlotCols, plot_index, plot_data, plot_label)\n",
    "\n",
    "# Create plots for the ensemble mean, observations, and a figure color bar.\n",
    "cplot, axs[7,2] = make_map_plot(numPlotRows, numPlotCols, 31, winter_trends_mean, 'EM')\n",
    "\n",
    "lats = obs_winter_trends.lat\n",
    "lons = obs_winter_trends.lon\n",
    "cplot, axs[7,3] = make_map_plot(numPlotRows, numPlotCols, 32, obs_winter_trends.tempanomaly, 'OBS')  \n",
    "\n",
    "cbar = fig.colorbar(cplot, ax=axs, orientation='horizontal', shrink = 0.7, pad = 0.02)\n",
    "cbar.ax.set_title('1979-2012 DJF surface air temperature trends (K/34 years)', fontSize = 16)\n",
    "cbar.set_ticks(contour_levels)\n",
    "cbar.set_ticklabels(contour_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure will appear above when ready. Compare with Fig. 4 of Kay et al. 2015 ([doi:10.1175/BAMS-D-13-00255.1](https://doi.org/10.1175/BAMS-D-13-00255.1)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gracefully destroy/close our cluster\n",
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
